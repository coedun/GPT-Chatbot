{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d379fa-8ed7-4ca5-a092-3bb7aebf480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0053f8d-f1fa-4fd6-bab2-373f9548d774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "probs = torch.tensor([0.1,0.9])\n",
    "\n",
    "# multinomial is a probability distribution\n",
    "# creates a distribution which reflects the probaibilites\n",
    "samples = torch.multinomial(probs, num_samples=10, replacement=True)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dbd584c-e6bf-4407-abec-02462a03fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3,4])\n",
    "out = torch.cat((tensor, torch.tensor([5])), dim=0)\n",
    "print(out)\n",
    "\"\"\" \n",
    "    useful for generating text in content, it'll start from zero and \n",
    "    use the probability distribution and based on the first character\n",
    "    to predict the probility of the next character\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75995cd7-fdec-453f-bc12-eb04e5b4094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.trill(torch.ones(5,5)) # triangle lower\n",
    "out\n",
    "\"\"\"\n",
    "    Important as when you try to predict the next token in the sequence\n",
    "    you only know what's in the current history.\n",
    "    Premise is to ensure we can't predict with the answer, but as we \n",
    "    increase in iteration we have more and more history\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574ba17-52dd-4c3b-9a67-365612fce063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_fill -> fills elements where the mask is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4c88103-4cb1-432f-9b49-9055a905a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.5356, -2.6911, -2.1538], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "sample = torch.tensor([10.,10.,10.])\n",
    "linear = nn.Linear(3,3,bias=False) # train on the weights and is very learnable\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "797f936c-1b06-4481-9f93-2581866733cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# create a tensor\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# apply softmax using the nn.functional.softmax()\n",
    "\n",
    "softmax_out = F.softmax(tensor1,dim=0)\n",
    "print(softmax_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "502bd73e-7516-4a7e-a782-b39062caae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "# Intialising embedding layer\n",
    "vocab_size = 1000\n",
    "embedding_dim = 100\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Create some input indices\n",
    "input_indices = torch.LongTensor([1,5,3,2])\n",
    "\n",
    "# Apply the embedding layer\n",
    "embedded_output = embedding(input_indices)\n",
    "\n",
    "print(embedded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2427bdea-0a4b-4708-8f60-1a16aeeb0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "b = torch.tensor([[7,8,9],[10,11,12]])\n",
    "\n",
    "print (a @ b)\n",
    "print(torch.matmul(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f1b8c-9d7d-4d9f-a9a0-f14f4c62e55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda gpt3",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
